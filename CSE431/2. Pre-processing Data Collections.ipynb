{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stylish-pencil",
   "metadata": {},
   "source": [
    "# Loading and tokenising a single document\n",
    "You can use the open() function to open one file in the Medical History of British India corpus. You need to specify the path to a file in the downloaded dataset and the mode of opening it (‘r’ for read). The path will be different to the one below depending on where you saved the data on your computer.\n",
    "\n",
    "The read() function is used to read the file. The file’s content (the text) is then stored as a string variable called india_raw.\n",
    "\n",
    "You can then tokenise the text and convert it to lowercase. You can check it has worked by printing out a slice of the list lower_india_tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "czech-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "french-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('nls-text-indiaPapers/74457530.txt','r')\n",
    "raw_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-speed",
   "metadata": {},
   "source": [
    "### Using word_tokenize() to tokenize the document\n",
    "#### For lower case, we use lower() on each entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reported-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(raw_data)\n",
    "lower_tokens = [word.lower() for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stone-cross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', '.', '1111', '(', 'sanitary', ')', ',', 'dated', 'ootacamund', ',']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_tokens[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-produce",
   "metadata": {},
   "source": [
    "# Loading and tokenising a corpus\n",
    "We can do the same for an entire collection of documents (a corpus). Here we choose a collection of raw text documents in a given directory. We will use the entire Medical History of British India collection as our dataset.\n",
    "\n",
    "To read the text files in this collection we can use the PlaintextCorpusReader class provided in the corpus package of NLTK. You need to specify the collection directory name and a wildcard for which files to read in the directory (e.g. .* for all files) and the text encoding of the files (in this case latin1). Using the words() method provided by NLTK, the text is automatically tokenised and stored in a list of words. As before, we can then lowercase the words in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "occupational-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "floral-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_root = 'nls-text-indiaPapers/'\n",
    "wordlists = PlaintextCorpusReader(corpus_root, '.*', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "clear-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens = wordlists.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "crazy-sheriff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No',\n",
       " '.',\n",
       " '1111',\n",
       " '(',\n",
       " 'Sanitary',\n",
       " '),',\n",
       " 'dated',\n",
       " 'Ootacamund',\n",
       " ',',\n",
       " 'the',\n",
       " '6th',\n",
       " 'October',\n",
       " '1876',\n",
       " '.',\n",
       " 'From']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tokens[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "based-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_corpus_tokens = [str(word).lower() for word in corpus_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "derived-capitol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no',\n",
       " '.',\n",
       " '1111',\n",
       " '(',\n",
       " 'sanitary',\n",
       " '),',\n",
       " 'dated',\n",
       " 'ootacamund',\n",
       " ',',\n",
       " 'the',\n",
       " '6th',\n",
       " 'october',\n",
       " '1876',\n",
       " '.',\n",
       " 'from']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_corpus_tokens[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "secondary-mixture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93568\n",
      "28345943\n"
     ]
    }
   ],
   "source": [
    "# Lowercase tokens of the file 74457530.txt from the 'nls-text-indiaPapers/' directory\n",
    "print(len(lower_tokens))\n",
    "\n",
    "# Lowercase tokens of the entire corpus or all the files from the 'nls-text-indiaPapers/' directory\n",
    "print(len(lower_corpus_tokens)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-oxford",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
