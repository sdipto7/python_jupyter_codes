{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "broke-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.text import Text\n",
    "import re\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "honest-concentrate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     C:\\Users\\DIPTO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('inaugural')\n",
    "\n",
    "from nltk.corpus import inaugural\n",
    "from nltk.text import Text\n",
    "\n",
    "inaugural_tokens=inaugural.words()\n",
    "inaugural_texts = Text(inaugural_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-parks",
   "metadata": {},
   "source": [
    "### Collocations\n",
    "##### A collocation is made up of two or more words that are commonly used together in English. Think of collocations as words that usually go together.\n",
    "\n",
    "We may want to see what terms are often used together. We can do this by looking for collocations in a text, i.e. two word tokens occurring together in the text more often than would be expected by chance.\n",
    "\n",
    "For this we need to import the nltk.collocations module and more specifically BigramAssocMeasures() and BigramCollocationFinder. We allow a window of 5 words between collocated words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "naughty-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramAssocMeasures\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(inaugural_tokens, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-electron",
   "metadata": {},
   "source": [
    "We then look for words that appear together 10 times or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "developing-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "finder.apply_freq_filter(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-madrid",
   "metadata": {},
   "source": [
    "A number of measures are available to score collocations or other associations including bigram_measures.likelihood_ratio. We apply this measure below and show the top ten collocated tokens (occuring in a window of 5 tokens with a frequency of 10 or more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cleared-spectacular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'of'),\n",
       " (\"'\", 's'),\n",
       " ('.', 'The'),\n",
       " ('.', 'We'),\n",
       " ('United', 'States'),\n",
       " ('has', 'been'),\n",
       " ('.', '.'),\n",
       " ('have', 'been'),\n",
       " ('.', 'It'),\n",
       " (',', 'and')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(bigram_measures.likelihood_ratio, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-projection",
   "metadata": {},
   "source": [
    "###### Task 1: Change the code above to display collocations in the inaugural speeches after stopwords, punctuation and single digits have been removed. Refer back to Section 7 on frequency distribution for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "subtle-radius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('United', 'States'),\n",
       " ('fellow', 'citizens'),\n",
       " ('let', 'us'),\n",
       " ('I', 'shall'),\n",
       " ('Let', 'us'),\n",
       " ('men', 'women'),\n",
       " ('four', 'years')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_these = set(stopwords.words('english') + list(string.punctuation) + list(string.digits))\n",
    "\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "\n",
    "filtered_text = [w for w in inaugural_tokens if not w in remove_these]\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(filtered_text, 5)\n",
    "\n",
    "finder.apply_freq_filter(10)\n",
    "finder.nbest(bigram_measures.likelihood_ratio, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-hazard",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
